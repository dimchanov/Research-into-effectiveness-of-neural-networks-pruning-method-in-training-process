{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qjJ8N5_UcS3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import random\n",
        "from torch.nn.utils import prune\n",
        "import tqdm.notebook as tqdm\n",
        "from functools import partial\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def set_global_seed(seed: int) -> None:\n",
        "    \"\"\"\n",
        "    Set global seed for reproducibility.\n",
        "    \"\"\"\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_global_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BiBiKb6YP9t"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "DEVICE = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda', 0)\n",
        "\n",
        "print(type(DEVICE), DEVICE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UMMwxhvpU-12"
      },
      "source": [
        "## Загрузка и обработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOqJYBz4UdLT"
      },
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomCrop(32, 4),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=(0.4914, 0.4822, 0.4465),\n",
        "        std=(0.2023, 0.1994, 0.2010)\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz4QEgy9VHe4"
      },
      "outputs": [],
      "source": [
        "ds_train = torchvision.datasets.CIFAR10(\n",
        "    root='./', train=True, transform=transform, download=True\n",
        ")\n",
        "ds_test = torchvision.datasets.CIFAR10(\n",
        "    root='./', train=False,\n",
        "    transform=torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=(0.4914, 0.4822, 0.4465),\n",
        "        std=(0.2023, 0.1994, 0.2010)\n",
        "    )\n",
        "    ]),\n",
        "    download=True\n",
        ")\n",
        "ds_train, ds_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "521NbBfAWo36"
      },
      "outputs": [],
      "source": [
        "tmean, tstd = transform.transforms[-1].mean, transform.transforms[-1].std\n",
        "tmean, tstd = np.array(tmean), np.array(tstd)\n",
        "\n",
        "inverse_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=-tmean / tstd,\n",
        "        std=1.0 / tstd\n",
        "    ),\n",
        "    torchvision.transforms.ToPILImage()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzfxJd-kUdN-"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 5, figsize=(13, 6))\n",
        "\n",
        "for idx, ds in enumerate((ds_train, ds_test)):\n",
        "    for jdx, kdx in enumerate(np.random.randint(0, len(ds), size=5)):\n",
        "        image, label = ds[kdx]\n",
        "        axes[idx, jdx].imshow(inverse_transform(image))\n",
        "        axes[idx, jdx].set_title(f'Метка: {label} -> {ds.classes[label]}')\n",
        "\n",
        "axes[0, 0].set_ylabel('Обучающая выборка')\n",
        "axes[1, 0].set_ylabel('Тестовая выборка')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDL5sxK5UdP9"
      },
      "outputs": [],
      "source": [
        "dl_train = torch.utils.data.DataLoader(\n",
        "    dataset=ds_train, batch_size=BATCH_SIZE,\n",
        "    num_workers=2, shuffle=True\n",
        ")\n",
        "dl_test = torch.utils.data.DataLoader(\n",
        "    dataset=ds_test, batch_size=BATCH_SIZE,\n",
        "    num_workers=2, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQZcJio3UNVP"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(torch.nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
        "        self.conv2 = torch.nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = torch.nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                torch.nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(torch.nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
        "        self.conv2 = torch.nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
        "        self.conv3 = torch.nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = torch.nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                torch.nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = torch.nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giQJOrp2UPUC"
      },
      "outputs": [],
      "source": [
        "conv_net = ResNet18()\n",
        "conv_net.load_state_dict(torch.load(GLOBAL_PATH + 'Models/ResNet18_27.11.2022-21_53.pth', map_location=DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQtOuyewlCMc"
      },
      "outputs": [],
      "source": [
        "def test_model(model, train_dataloader) -> float:\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_accuracies = []\n",
        "        for images, labels in tqdm.tqdm(train_dataloader, total=len(train_dataloader), leave=False):\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs  = model(images)\n",
        "            train_accuracies.append(torch.sum(outputs.argmax(dim=1) == labels)/labels.shape[0])\n",
        "        return float((sum(train_accuracies) / len(train_accuracies)).cpu() * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WskrNvGhnx4x"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--ZA8MRnYZFe"
      },
      "outputs": [],
      "source": [
        "def count_parameters(net) -> int:\n",
        "  count_params = 0\n",
        "  count_zero_params = 0\n",
        "  for name, module in net.named_modules():\n",
        "      if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "          count_params += module.weight.numel()\n",
        "          count_zero_params += torch.sum(module.weight == 0)\n",
        "          sparsity = 100. * float(torch.sum(module.weight == 0)) / float(module.weight.nelement())\n",
        "          print(f'Sparsity in {name}.weight with {module.weight.numel()} parameters: {sparsity:0.3f}%')\n",
        "  print(f'Global sparsity: {100. * (float(count_zero_params) / float(count_params)):0.3f}%')\n",
        "  return count_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG9w9i8WNTLa"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "drffE2srgFlp"
      },
      "source": [
        "## Euclidean norm prune unstructured\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP_VRf_Rig6p"
      },
      "outputs": [],
      "source": [
        "conv_net = ResNet18()\n",
        "conv_net.load_state_dict(torch.load(GLOBAL_PATH + 'Models/ResNet18_27.11.2022-21_53.pth', map_location=DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGUf_DgPgEv4"
      },
      "outputs": [],
      "source": [
        "def prune_euclidean_norm_unstructured(net, amount) -> torch.tensor:\n",
        "    modules_mask_list = []\n",
        "    for name, module in conv_net.named_modules():\n",
        "          if isinstance(module, torch.nn.Conv2d):\n",
        "              dist_matrix = torch.cdist(module.weight.flatten(start_dim=1),\n",
        "                                        module.weight.flatten(start_dim=1)\n",
        "                                      ).cpu().detach().numpy()\n",
        "              dist_matrix[np.tril_indices(len(dist_matrix))] = np.nan\n",
        "\n",
        "              module_norm = np.nanmin(dist_matrix[:-1], axis=1)\n",
        "\n",
        "              prune_mask = np.full(len(module_norm) + 1, True)\n",
        "              prune_mask[np.argsort(module_norm)[:round(len(prune_mask) * amount)]] = False\n",
        "              prune_mask = torch.tensor(prune_mask)\n",
        "\n",
        "              mask = torch.ones_like(module.weight)\n",
        "              mask[~prune_mask] = 0\n",
        "              prune.custom_from_mask(module=module, name='weight', mask=mask)\n",
        "              filters_count = len(module.weight)\n",
        "              cur_module_df = pd.DataFrame(dist_matrix,\n",
        "                                           columns=np.arange(filters_count))\n",
        "              plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
        "              plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
        "              plt.rc('ytick', labelsize=14)    # fontsize of the tick labels\n",
        "              fig, ax = plt.subplots(figsize=(17, 10))\n",
        "              sns.heatmap(ax=ax, data=cur_module_df,\n",
        "                  square=True,\n",
        "                  cmap='GnBu_r',\n",
        "                  cbar_kws={'label': 'Евклидово расстояние'})\n",
        "              ax.set_xlabel('Номер фильтра')\n",
        "              ax.set_ylabel('Номер фильтра')\n",
        "              new_ticks = range(0, filters_count + 1, filters_count // 4)\n",
        "              plt.xticks(new_ticks, new_ticks, rotation ='horizontal')\n",
        "              plt.yticks(new_ticks, new_ticks, rotation ='horizontal')\n",
        "              plt.show()\n",
        "\n",
        "              modules_mask_list.append(prune_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGvxJStiaJ4h"
      },
      "outputs": [],
      "source": [
        "prune_euclidean_norm_unstructured(conv_net, 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dasnpkKBi50j"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzkrXrtJHE1L"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8lfeFR6IgaS"
      },
      "outputs": [],
      "source": [
        "def apply_mask(net, buffer):\n",
        "    for name, module in conv_net.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            buffer[name + '.weight_mask']\n",
        "            prune.custom_from_mask(module=module, name='weight', mask=buffer[name + '.weight_mask'])\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW-pEEeqKu5Y"
      },
      "outputs": [],
      "source": [
        "apply_mask(conv_net, dict(conv_net.named_buffers()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ_3Rl4hUdXi"
      },
      "outputs": [],
      "source": [
        "def training_loop(n_epochs, network, loss_fn, optimizer,scheduler, dl_train, dl_test, device):\n",
        "    '''\n",
        "    :param int n_epochs: Число итераций оптимизации\n",
        "    :param torch.nn.Module network: Нейронная сеть\n",
        "    :param Callable loss_fn: Функция потерь\n",
        "    :param torch.nn.Optimizer optimizer: Оптимизатор\n",
        "    :param torch.utils.data.DataLoader dl_train: Даталоадер для обучающей выборки\n",
        "    :param torch.utils.data.DataLoader dl_test: Даталоадер для тестовой выборки\n",
        "    :param torch.Device device: Устройство на котором будут происходить вычисления\n",
        "    :returns: Списки значений функции потерь и точности на обучающей и тестовой выборках после каждой итерации\n",
        "    '''\n",
        "    buffer = dict(network.named_buffers())\n",
        "    loss_fn.to(device)\n",
        "    train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
        "    pbar = tqdm.tqdm(range(n_epochs), total=n_epochs, leave=False)\n",
        "    for epoch in (pbar):\n",
        "        network.train()\n",
        "\n",
        "        # Итерация обучения сети\n",
        "        tmp_train_losses, tmp_train_accuracies = [], []\n",
        "        for images, labels in tqdm.tqdm(dl_train, total=len(dl_train), leave=False):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs  = network(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            apply_mask(network, buffer)\n",
        "\n",
        "            tmp_train_losses.append(loss)\n",
        "            tmp_train_accuracies.append(torch.sum(outputs.argmax(dim=1) == labels)/labels.shape[0])\n",
        "\n",
        "        train_losses.append((sum(tmp_train_losses) / len(tmp_train_losses)).cpu())\n",
        "        train_accuracies.append((sum(tmp_train_accuracies) / len(tmp_train_accuracies)).cpu() * 100)\n",
        "        # Оцениваем качество модели каждые 3 итерации\n",
        "        if epoch % 1 == 0 or epoch == n_epochs - 1:\n",
        "            # Переводим сеть в инференс режим\n",
        "            network.eval()\n",
        "\n",
        "            # При тестировании сети нет необходимости считать градиенты, поэтому можно отключить автоматическое дифференцирование\n",
        "            #   для ускорения операций\n",
        "            with torch.no_grad():\n",
        "                tmp_test_losses, tmp_test_accuracies = [], []\n",
        "                for images, labels in tqdm.tqdm(dl_test, total=len(dl_test), leave=False):\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    outputs  = network(images)\n",
        "\n",
        "                    tmp_test_losses.append(loss_fn(outputs, labels))\n",
        "                    tmp_test_accuracies.append(torch.sum(outputs.argmax(dim=1) == labels)/labels.shape[0])\n",
        "\n",
        "                test_losses.append((sum(tmp_test_losses) / len(tmp_test_losses)).cpu())\n",
        "                test_accuracies.append((sum(tmp_test_accuracies) / len(tmp_test_accuracies)).cpu() * 100)\n",
        "\n",
        "            pbar.set_description(\n",
        "                'Loss (Train/Test): {0:.3f}/{1:.3f}. Accuracy, % (Train/Test): {2:.2f}/{3:.2f}\\n'.format(\n",
        "                    train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "                )\n",
        "            )\n",
        "\n",
        "    return train_losses, test_losses, train_accuracies, test_accuracies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nXGhmSz1neoj"
      },
      "source": [
        "## 20% L1 norm prune unstructured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WJec6aEncpu"
      },
      "outputs": [],
      "source": [
        "conv_net = ResNet18()\n",
        "conv_net.load_state_dict(torch.load(GLOBAL_PATH + 'Models/ResNet18_27.11.2022-21_53.pth', map_location=DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX1aosL2nwro"
      },
      "outputs": [],
      "source": [
        "prune_euclidean_norm_unstructured(conv_net, 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aodi0bQloBFZ"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX_t5jiRoEmI"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xw4nd0QnZ3j"
      },
      "outputs": [],
      "source": [
        "train_func = partial(\n",
        "    training_loop, n_epochs=2, loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "    dl_train=dl_train, dl_test=dl_test, device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAZNeUBbQs5N"
      },
      "outputs": [],
      "source": [
        "conv_net.to(DEVICE);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90mXghy6s2_4"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(conv_net.parameters(), lr=0.05 * 2e-1, momentum=0.9, weight_decay=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oExMOCiWnZ6S"
      },
      "outputs": [],
      "source": [
        "train_losses, test_losses, train_accs, test_accs = train_func(\n",
        "    network=conv_net,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMTli1qunZ9Z"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "ax.plot(train_accs, label=\"Точность на обучении\", color='red', marker='.', linestyle='-.')\n",
        "ax.plot(test_accs, label=\"Точность на тесте\", color='red', marker='*')\n",
        "\n",
        "ax.set_xlabel(\"Номер эпохи\")\n",
        "ax.set_ylabel(\"$\\%$\")\n",
        "\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5Ew3tHey5He"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCIkFBMsoWWA"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2ut7g9txoYnh"
      },
      "source": [
        "## 40% L1 norm prune unstructured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjXamLnvrJ70"
      },
      "outputs": [],
      "source": [
        "conv_net = ResNet18()\n",
        "conv_net.load_state_dict(torch.load(GLOBAL_PATH + 'Models/ResNet18_27.11.2022-21_53.pth', map_location=DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnMmOSVFrKAK"
      },
      "outputs": [],
      "source": [
        "prune_euclidean_norm_unstructured(conv_net, 0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx_JlPnOrKFf"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCxN_ik0rKIH"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Vma31SbrKK5"
      },
      "outputs": [],
      "source": [
        "train_func = partial(\n",
        "    training_loop, n_epochs=2, loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "    dl_train=dl_train, dl_test=dl_test, device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlxLQWgjtXLd"
      },
      "outputs": [],
      "source": [
        "conv_net.to(DEVICE);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efDB1iActV9g"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(conv_net.parameters(), lr=0.05 * 3e-1, momentum=0.9, weight_decay=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3TIcqS2tWAU"
      },
      "outputs": [],
      "source": [
        "train_losses, test_losses, train_accs, test_accs = train_func(\n",
        "    network=conv_net,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "066bBECJrKND"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "ax.plot(train_accs, label=\"Точность на обучении\", color='red', marker='.', linestyle='-.')\n",
        "ax.plot(test_accs, label=\"Точность на тесте\", color='red', marker='*')\n",
        "\n",
        "ax.set_xlabel(\"Номер эпохи\")\n",
        "ax.set_ylabel(\"$\\%$\")\n",
        "\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5m0TrL6td0-"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SA2TSHmtd3q"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "42u-gUrWdfqi"
      },
      "source": [
        "## 60% L1 norm prune unstructured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDwWVqD8td64"
      },
      "outputs": [],
      "source": [
        "conv_net = ResNet18()\n",
        "conv_net.load_state_dict(torch.load(GLOBAL_PATH + 'Models/ResNet18_27.11.2022-21_53.pth', map_location=DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTO5uy1RrKPz"
      },
      "outputs": [],
      "source": [
        "prune_euclidean_norm_unstructured(conv_net, 0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB5diXodrKTz"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bmri-rMeYil"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EVZb6oBeYlW"
      },
      "outputs": [],
      "source": [
        "train_func = partial(\n",
        "    training_loop, n_epochs=2, loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "    dl_train=dl_train, dl_test=dl_test, device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsYsSsgMeYoC"
      },
      "outputs": [],
      "source": [
        "conv_net.to(DEVICE);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5Am_8AkeYrt"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(conv_net.parameters(), lr=0.05 * 5e-1, momentum=0.9, weight_decay=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDkJUGXUelWr"
      },
      "outputs": [],
      "source": [
        "train_losses, test_losses, train_accs, test_accs = train_func(\n",
        "    network=conv_net,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZErGz7eHelaH"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "ax.plot(train_accs, label=\"Точность на обучении\", color='red', marker='.', linestyle='-.')\n",
        "ax.plot(test_accs, label=\"Точность на тесте\", color='red', marker='*')\n",
        "\n",
        "ax.set_xlabel(\"Номер эпохи\")\n",
        "ax.set_ylabel(\"$\\%$\")\n",
        "\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5TRXjAmeleE"
      },
      "outputs": [],
      "source": [
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf7Fef3melhi"
      },
      "outputs": [],
      "source": [
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-jcj3GKelk7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZpZEYSbfdld"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Va3YtrneYvC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "drffE2srgFlp",
        "nXGhmSz1neoj",
        "2ut7g9txoYnh",
        "42u-gUrWdfqi"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
