{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qjJ8N5_UcS3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import torch\n",
        "import math\n",
        "from torch.nn.utils import prune\n",
        "import tqdm.notebook as tqdm\n",
        "from functools import partial\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def set_global_seed(seed: int) -> None:\n",
        "    \"\"\"\n",
        "    Set global seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_global_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BiBiKb6YP9t"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "DEVICE = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda', 0)\n",
        "\n",
        "print(type(DEVICE), DEVICE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UMMwxhvpU-12"
      },
      "source": [
        "## Загрузка и обработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOqJYBz4UdLT"
      },
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomCrop(32, 4),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz4QEgy9VHe4"
      },
      "outputs": [],
      "source": [
        "ds_train = torchvision.datasets.CIFAR10(\n",
        "    root='./', train=True, transform=transform, download=True\n",
        ")\n",
        "ds_test = torchvision.datasets.CIFAR10(\n",
        "    root='./', train=False,\n",
        "    transform=torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )]),\n",
        "    download=True\n",
        ")\n",
        "ds_train, ds_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "521NbBfAWo36"
      },
      "outputs": [],
      "source": [
        "tmean, tstd = transform.transforms[-1].mean, transform.transforms[-1].std\n",
        "tmean, tstd = np.array(tmean), np.array(tstd)\n",
        "\n",
        "inverse_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=-tmean / tstd,\n",
        "        std=1.0 / tstd\n",
        "    ),\n",
        "    torchvision.transforms.ToPILImage()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzfxJd-kUdN-"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(13, 6))\n",
        "\n",
        "for idx, ds in enumerate((ds_train, ds_test)):\n",
        "    for jdx, kdx in enumerate(np.random.randint(0, len(ds), size=5)):\n",
        "        image, label = ds[kdx]\n",
        "        axes[idx, jdx].imshow(inverse_transform(image))\n",
        "        axes[idx, jdx].set_title(f'Метка: {label} -> {ds.classes[label]}')\n",
        "\n",
        "axes[0, 0].set_ylabel('Обучающая выборка')\n",
        "axes[1, 0].set_ylabel('Тестовая выборка')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDL5sxK5UdP9"
      },
      "outputs": [],
      "source": [
        "dl_train = torch.utils.data.DataLoader(\n",
        "    dataset=ds_train, batch_size=BATCH_SIZE,\n",
        "    num_workers=2, shuffle=True\n",
        ")\n",
        "dl_test = torch.utils.data.DataLoader(\n",
        "    dataset=ds_test, batch_size=BATCH_SIZE,\n",
        "    num_workers=2, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQZcJio3UNVP"
      },
      "outputs": [],
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "\n",
        "    def __init__(self, n_classes=10, use_batchnorm=False, dropout_p=0.0):\n",
        "        '''\n",
        "        :param int n_classes: Число выходных признаков\n",
        "        :param bool use_batchnorm: Использовать ли батчнорм между свёрточными слоями\n",
        "        :param float dropout_p: Вероятность обнуления активации слоем Dropout\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_channels = 3\n",
        "        self.features = torch.nn.Sequential()\n",
        "        for cfg_item in self.cfg:\n",
        "            if isinstance(cfg_item, int):\n",
        "                self.features.append(torch.nn.Conv2d(self.in_channels,\n",
        "                                                     out_channels=int(cfg_item),\n",
        "                                                     kernel_size=3,\n",
        "                                                     padding=1))\n",
        "                if use_batchnorm:\n",
        "                    self.features.append(torch.nn.BatchNorm2d(int(cfg_item)))\n",
        "                self.features.append(torch.nn.ReLU(inplace=True))\n",
        "                self.in_channels = int(cfg_item)\n",
        "            elif cfg_item == \"M\":\n",
        "                self.features.append(torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
        "\n",
        "        # self.avgpool = torch.nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=512, out_features=512),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Dropout(p=dropout_p),\n",
        "            torch.nn.Linear(in_features=512, out_features=512),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Dropout(p=dropout_p),\n",
        "            torch.nn.Linear(in_features=512, out_features=10)\n",
        "        )\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        # x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQtOuyewlCMc"
      },
      "outputs": [],
      "source": [
        "def test_model(model, train_dataloader) -> float:\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_accuracies = []\n",
        "        for images, labels in tqdm.tqdm(train_dataloader, total=len(train_dataloader), leave=False):\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs  = model(images)\n",
        "            train_accuracies.append(torch.sum(outputs.argmax(dim=1) == labels)/labels.shape[0])\n",
        "        return float((sum(train_accuracies) / len(train_accuracies)).cpu() * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--ZA8MRnYZFe"
      },
      "outputs": [],
      "source": [
        "def count_parameters(net) -> int:\n",
        "  count_params = 0\n",
        "  count_zero_params = 0\n",
        "  for name, module in net.named_modules():\n",
        "      if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "          count_params += module.weight.numel()\n",
        "          count_zero_params += torch.sum(module.weight == 0)\n",
        "          sparsity = 100. * float(torch.sum(module.weight == 0)) / float(module.weight.nelement())\n",
        "          print(f'Module len: {len(module.weight)}; Sparsity in {name}.weight with {module.weight.numel()} parameters: {sparsity:0.3f}%')\n",
        "  print(f'Global sparsity: {100. * (float(count_zero_params) / float(count_params)):0.3f}%')\n",
        "  return count_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziGtrqo9RvMt"
      },
      "outputs": [],
      "source": [
        "PRUN_PERCENT = 10\n",
        "N_PERCENT = 5\n",
        "M_PERCENT = 10\n",
        "DUMMY_PARAMS_PERCENT = 90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLYGSoiNPXq2"
      },
      "outputs": [],
      "source": [
        "class Relevance():\n",
        "    def __init__(self, model, dummy_percent, n_percent, m_percent) -> None:\n",
        "        self.n_percent = n_percent\n",
        "        self.module_size_list = []\n",
        "        self.n_list = []\n",
        "        self.dummy_size_list = []\n",
        "        self.m_list = []\n",
        "        self.r_list = []\n",
        "        self.q_list = []\n",
        "\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                module_size = module.weight.shape[0]\n",
        "                self.module_size_list.append(module_size)\n",
        "                self.n_list.append(round(module_size * (n_percent / 100)))\n",
        "                dummy_size = round(module_size * (dummy_percent / 100))\n",
        "                self.dummy_size_list.append(dummy_size)\n",
        "                self.m_list.append(round(dummy_size * (m_percent / 100)))\n",
        "\n",
        "                self.r_list.append(torch.zeros(module_size))\n",
        "                self.q_list.append(torch.zeros(dummy_size))\n",
        "\n",
        "\n",
        "        self.criterion_value_list = [0]\n",
        "\n",
        "        self.feature_indexes_list = [np.arange(n) for n in self.module_size_list]\n",
        "        self.feature_mask_list = []\n",
        "        self.dummy_feature_mask_list = []\n",
        "\n",
        "    def _del_mask(self, model):\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                if prune.is_pruned(module):\n",
        "                    with torch.no_grad():\n",
        "                        self._tensor_name = 'weight'\n",
        "                        if hasattr(module, self._tensor_name):\n",
        "                            delattr(module, self._tensor_name)\n",
        "                        orig = module._parameters[self._tensor_name + \"_orig\"]\n",
        "                        del module._parameters[self._tensor_name + \"_orig\"]\n",
        "                        del module._buffers[self._tensor_name + \"_mask\"]\n",
        "                        module._forward_pre_hooks = OrderedDict()\n",
        "                        setattr(module, self._tensor_name, orig)\n",
        "        self.feature_mask_list = []\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def update_mask(self, model):\n",
        "        feature_mask_list = []\n",
        "        dummy_feature_mask_list = []\n",
        "        layer_num = 0\n",
        "        self._del_mask(model)\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                feature_indexes_sample = random.sample(list(self.feature_indexes_list[layer_num]), self.n_list[layer_num])\n",
        "                feature_mask = torch.zeros(self.module_size_list[layer_num])\n",
        "                feature_mask[self.feature_indexes_list[layer_num]] = 1\n",
        "                feature_mask[feature_indexes_sample] = 0\n",
        "                feature_mask_list.append(feature_mask)\n",
        "\n",
        "                dummy_feature_indexes = np.arange(self.dummy_size_list[layer_num])\n",
        "                dummy_feature_indexes_sample = random.sample(list(dummy_feature_indexes), self.m_list[layer_num])\n",
        "                dummy_feature_mask = torch.ones(self.dummy_size_list[layer_num])\n",
        "                dummy_feature_mask[dummy_feature_indexes_sample] = 0\n",
        "                dummy_feature_mask_list.append(dummy_feature_mask)\n",
        "                layer_num += 1\n",
        "\n",
        "        self.feature_mask_list = feature_mask_list\n",
        "\n",
        "        self.dummy_feature_mask_list = dummy_feature_mask_list\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def apply_mask(self, model):\n",
        "        layer_num = 0\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                if (self.feature_mask_list):\n",
        "                    weight_mask = torch.ones_like(module.weight)\n",
        "                    weight_mask[~torch.tensor(self.feature_mask_list[layer_num], dtype=bool)] = 0\n",
        "                    prune.custom_from_mask(module=module, name='weight', mask=weight_mask)\n",
        "                elif (self.feature_indexes_list):\n",
        "                    feature_mask = torch.zeros(self.module_size_list[layer_num])\n",
        "                    feature_mask[self.feature_indexes_list[layer_num]] = 1\n",
        "                    weight_mask = torch.ones_like(module.weight)\n",
        "                    weight_mask[~torch.tensor(feature_mask, dtype=bool)] = 0\n",
        "                    prune.custom_from_mask(module=module, name='weight', mask=weight_mask)\n",
        "                layer_num += 1\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def update_relevance(self, criterion_value):\n",
        "        for i in range(len(self.r_list)):\n",
        "            cur_delta = (criterion_value - np.mean(self.criterion_value_list))\n",
        "            self.r_list[i] += cur_delta * self.feature_mask_list[i].flatten()\n",
        "            self.q_list[i] += cur_delta * self.dummy_feature_mask_list[i].flatten()\n",
        "\n",
        "        self.criterion_value_list.append(criterion_value)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def cut_by_probability(self):\n",
        "        module_count = len(self.r_list)\n",
        "        for i in range(module_count):\n",
        "            mu = float(torch.mean(self.q_list[i]))\n",
        "            sigma = float(torch.std(self.q_list[i]))\n",
        "            probability_list = [norm.cdf(r, mu, sigma) for r in self.r_list[i][self.feature_indexes_list[i]]]\n",
        "            prune_indexes = np.argsort(probability_list)[:self.n_list[i]]\n",
        "            print(len(prune_indexes))\n",
        "            self.feature_indexes_list[i] = np.array([idx for idx in self.feature_indexes_list[i] if idx not in self.feature_indexes_list[i][prune_indexes]])\n",
        "\n",
        "            self.r_list[i] = torch.zeros(self.module_size_list[i])\n",
        "            self.q_list[i] = torch.zeros(self.dummy_size_list[i])\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ_3Rl4hUdXi"
      },
      "outputs": [],
      "source": [
        "def training_loop(n_epochs, network, loss_fn, optimizer,scheduler, dl_train, dl_test, device):\n",
        "    '''\n",
        "    :param int n_epochs: Число итераций оптимизации\n",
        "    :param torch.nn.Module network: Нейронная сеть\n",
        "    :param Callable loss_fn: Функция потерь\n",
        "    :param torch.nn.Optimizer optimizer: Оптимизатор\n",
        "    :param torch.utils.data.DataLoader dl_train: Даталоадер для обучающей выборки\n",
        "    :param torch.utils.data.DataLoader dl_test: Даталоадер для тестовой выборки\n",
        "    :param torch.Device device: Устройство на котором будут происходить вычисления\n",
        "    :returns: Списки значений функции потерь и точности на обучающей и тестовой выборках после каждой итерации\n",
        "    '''\n",
        "    loss_fn.to(device)\n",
        "    train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
        "    pbar = tqdm.tqdm(range(n_epochs), total=n_epochs, leave=False)\n",
        "    for epoch in (pbar):\n",
        "\n",
        "        # Итерация обучения сети\n",
        "        for batch_idx, (images, labels) in enumerate(tqdm.tqdm(dl_train, total=len(dl_train), leave=False)):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            global_idx = (epoch * len(dl_train) + batch_idx)\n",
        "\n",
        "            if global_idx < 21896 and global_idx %  test_relevance.n_percent == 0:\n",
        "                test_relevance.update_mask(network)\n",
        "            else:\n",
        "                test_relevance._del_mask(network)\n",
        "            test_relevance.apply_mask(network)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(network(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            if global_idx < 21896 and global_idx % test_relevance.n_percent == 0:\n",
        "                test_relevance.update_relevance(float(loss))\n",
        "\n",
        "            if global_idx != 0 and global_idx % 5474 == 0:\n",
        "                print('!' * 100)\n",
        "                test_relevance._del_mask(network)\n",
        "                count_parameters(network)\n",
        "                test_relevance.cut_by_probability()\n",
        "                test_relevance.apply_mask(network)\n",
        "                count_parameters(network)\n",
        "                print('!' * 100)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Оцениваем качество модели каждые 3 итерации\n",
        "        if epoch % 3 == 0 or epoch == n_epochs - 1:\n",
        "            # Переводим сеть в инференс режим\n",
        "            network.eval()\n",
        "\n",
        "            # При тестировании сети нет необходимости считать градиенты, поэтому можно отключить автоматическое дифференцирование\n",
        "            #   для ускорения операций\n",
        "            with torch.no_grad():\n",
        "                # Вычисление качества и функции потерь на обучающей выборке\n",
        "                tmp_train_losses, tmp_train_accuracies = [], []\n",
        "                for images, labels in tqdm.tqdm(dl_train, total=len(dl_train), leave=False):\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    test_relevance.apply_mask(network)\n",
        "                    outputs  = network(images)\n",
        "                    test_relevance._del_mask(network)\n",
        "\n",
        "                    tmp_train_losses.append(loss_fn(outputs, labels))\n",
        "                    tmp_train_accuracies.append(torch.sum(outputs.argmax(dim=1) == labels)/labels.shape[0])\n",
        "\n",
        "                train_losses.append((sum(tmp_train_losses) / len(tmp_train_losses)).cpu())\n",
        "                train_accuracies.append((sum(tmp_train_accuracies) / len(tmp_train_accuracies)).cpu() * 100)\n",
        "                # Вычисление качества и функции потерь на тестовой выборке\n",
        "                tmp_test_losses, tmp_test_accuracies = [], []\n",
        "                for images, labels in tqdm.tqdm(dl_test, total=len(dl_test), leave=False):\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    test_relevance.apply_mask(network)\n",
        "                    outputs  = network(images)\n",
        "                    test_relevance._del_mask(network)\n",
        "\n",
        "                    tmp_test_losses.append(loss_fn(outputs, labels))\n",
        "                    tmp_test_accuracies.append(torch.sum(outputs.argmax(dim=1) == labels)/labels.shape[0])\n",
        "\n",
        "                test_losses.append((sum(tmp_test_losses) / len(tmp_test_losses)).cpu())\n",
        "                test_accuracies.append((sum(tmp_test_accuracies) / len(tmp_test_accuracies)).cpu() * 100)\n",
        "\n",
        "            pbar.set_description(\n",
        "                'Loss (Train/Test): {0:.3f}/{1:.3f}. Accuracy, % (Train/Test): {2:.2f}/{3:.2f}\\n'.format(\n",
        "                    train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "                )\n",
        "            )\n",
        "\n",
        "    return train_losses, test_losses, train_accuracies, test_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6j0BZR84Igq"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qOGnMdCx6f-C"
      },
      "source": [
        "## 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tSM2ZfNO3JO"
      },
      "outputs": [],
      "source": [
        "N_PERCENT = 5\n",
        "M_PERCENT = 10\n",
        "DUMMY_PARAMS_PERCENT = 90\n",
        "\n",
        "train_func = partial(\n",
        "    training_loop, n_epochs=70, loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "    dl_train=dl_train, dl_test=dl_test, device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqUM1N_iO4qH"
      },
      "outputs": [],
      "source": [
        "conv_net = ConvNet()\n",
        "conv_net.to(DEVICE)\n",
        "optimizer = torch.optim.SGD(conv_net.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)\n",
        "\n",
        "test_relevance = Relevance(conv_net, DUMMY_PARAMS_PERCENT, N_PERCENT, M_PERCENT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0uPlYcpO7nj"
      },
      "outputs": [],
      "source": [
        "train_losses, test_losses, train_accs, test_accs = train_func(\n",
        "    network=conv_net,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-mgKYNLf5_E"
      },
      "outputs": [],
      "source": [
        "test_relevance.apply_mask(conv_net)\n",
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EGdH7X9CPs-"
      },
      "outputs": [],
      "source": [
        "test_relevance.apply_mask(conv_net)\n",
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WemixQy3gabG"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "np.save(GLOBAL_PATH + f'/VGG_train_accuracy_prun_20_{time.strftime(\"%d.%m.%Y-%H:%M\")}.npy', train_accs)\n",
        "np.save(GLOBAL_PATH + f'/VGG_test_accuracy_prun_20_{time.strftime(\"%d.%m.%Y-%H:%M\")}.npy', test_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXn7AOrAPEru"
      },
      "outputs": [],
      "source": [
        "SMALL_SIZE = 16\n",
        "MEDIUM_SIZE = 10\n",
        "BIGGER_SIZE = 8\n",
        "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
        "ax.plot(np.arange(len(train_accs)) * 3, train_accs, label=\"Точность на обучении\", color='red', marker='.', linestyle='-.')\n",
        "ax.plot(np.arange(len(test_accs)) * 3, test_accs, label=\"Точность на тесте\", color='red', marker='*')\n",
        "\n",
        "ax.set_xlabel(\"Номер эпохи\")\n",
        "ax.set_ylabel(\"Точность, %\")\n",
        "\n",
        "ax.grid(True)\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "# fig.text(\n",
        "#     0.5, 0.5, 'Только для ознакомления',\n",
        "#     fontsize=40, color='gray', alpha=0.6,\n",
        "#     ha='center', va='center', rotation='30'\n",
        "# )\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-WZ6rt9WPjG"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0XDtCCDs1yaK"
      },
      "source": [
        "## 40%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr8OY1JD6szt"
      },
      "outputs": [],
      "source": [
        "N_PERCENT = 10\n",
        "M_PERCENT = 10\n",
        "DUMMY_PARAMS_PERCENT = 90\n",
        "\n",
        "train_func = partial(\n",
        "    training_loop, n_epochs=70, loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "    dl_train=dl_train, dl_test=dl_test, device=DEVICE\n",
        ")\n",
        "conv_net = ConvNet()\n",
        "conv_net.to(DEVICE)\n",
        "optimizer = torch.optim.SGD(conv_net.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)\n",
        "\n",
        "test_relevance = Relevance(conv_net, DUMMY_PARAMS_PERCENT, N_PERCENT, M_PERCENT)\n",
        "train_losses, test_losses, train_accs, test_accs = train_func(\n",
        "    network=conv_net,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrdWSbwx179I"
      },
      "outputs": [],
      "source": [
        "test_relevance.apply_mask(conv_net)\n",
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgFq79QM1-iX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "np.save(GLOBAL_PATH + f'/VGG_train_accuracy_prun_40_{time.strftime(\"%d.%m.%Y-%H:%M\")}.npy', train_accs)\n",
        "np.save(GLOBAL_PATH + f'/VGG_test_accuracy_prun_40_{time.strftime(\"%d.%m.%Y-%H:%M\")}.npy', test_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaBhG4Uk1-kv"
      },
      "outputs": [],
      "source": [
        "SMALL_SIZE = 16\n",
        "MEDIUM_SIZE = 10\n",
        "BIGGER_SIZE = 8\n",
        "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
        "ax.plot(np.arange(len(train_accs)) * 3, train_accs, label=\"Точность на обучении\", color='red', marker='.', linestyle='-.')\n",
        "ax.plot(np.arange(len(test_accs)) * 3, test_accs, label=\"Точность на тесте\", color='red', marker='*')\n",
        "\n",
        "ax.set_xlabel(\"Номер эпохи\")\n",
        "ax.set_ylabel(\"Точность, %\")\n",
        "\n",
        "ax.grid(True)\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "# fig.text(\n",
        "#     0.5, 0.5, 'Только для ознакомления',\n",
        "#     fontsize=40, color='gray', alpha=0.6,\n",
        "#     ha='center', va='center', rotation='30'\n",
        "# )\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JQLrKfFH6tM8"
      },
      "source": [
        "## 60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2gtc1W7PKBB"
      },
      "outputs": [],
      "source": [
        "N_PERCENT = 15\n",
        "M_PERCENT = 10\n",
        "DUMMY_PARAMS_PERCENT = 90\n",
        "\n",
        "train_func = partial(\n",
        "    training_loop, n_epochs=70, loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "    dl_train=dl_train, dl_test=dl_test, device=DEVICE\n",
        ")\n",
        "conv_net = ConvNet()\n",
        "conv_net.to(DEVICE)\n",
        "optimizer = torch.optim.SGD(conv_net.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)\n",
        "\n",
        "test_relevance = Relevance(conv_net, DUMMY_PARAMS_PERCENT, N_PERCENT, M_PERCENT)\n",
        "train_losses, test_losses, train_accs, test_accs = train_func(\n",
        "    network=conv_net,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFRoLJtyIPMI"
      },
      "outputs": [],
      "source": [
        "test_relevance.apply_mask(conv_net)\n",
        "test_model(conv_net, dl_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b9APchDPKIJ"
      },
      "outputs": [],
      "source": [
        "test_relevance.apply_mask(conv_net)\n",
        "count_parameters(conv_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf0csEwpJiF2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "np.save(GLOBAL_PATH + f'/VGG_train_accuracy_prun_60_{time.strftime(\"%d.%m.%Y-%H:%M\")}.npy', train_accs)\n",
        "np.save(GLOBAL_PATH + f'/VGG_test_accuracy_prun_60_{time.strftime(\"%d.%m.%Y-%H:%M\")}.npy', test_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEfJfEm36mcs"
      },
      "outputs": [],
      "source": [
        "SMALL_SIZE = 16\n",
        "MEDIUM_SIZE = 10\n",
        "BIGGER_SIZE = 8\n",
        "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
        "ax.plot(np.arange(len(train_accs)) * 3, train_accs, label=\"Точность на обучении\", color='red', marker='.', linestyle='-.')\n",
        "ax.plot(np.arange(len(test_accs)) * 3, test_accs, label=\"Точность на тесте\", color='red', marker='*')\n",
        "\n",
        "ax.set_xlabel(\"Номер эпохи\")\n",
        "ax.set_ylabel(\"Точность, %\")\n",
        "\n",
        "ax.grid(True)\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "# fig.text(\n",
        "#     0.5, 0.5, 'Только для ознакомления',\n",
        "#     fontsize=40, color='gray', alpha=0.6,\n",
        "#     ha='center', va='center', rotation='30'\n",
        "# )\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1qmsM966mfF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQQB5dTn6mhf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7r7Uygl6mjX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
